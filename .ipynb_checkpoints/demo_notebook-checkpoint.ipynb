{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# <center>Data Sourcing Techniques and Data Science Methods </center>\n",
    "_Leveraging Data Science 2019 SIOP Master Tutorial_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Data science’s focus on extremely large datasets has led to the development of many tools and analytic approaches optimized for those datasets, and many of these tools and approaches bring great value to improve the conclusions developed\n",
    "by IOs, even when data isn’t that big. \n",
    "\n",
    "Some of these concepts & tools are new to many people in IO but most are not as foreign as they appear initially. \n",
    "\n",
    "We’ll be discussing two general types of data science tools and approaches that have potential to help IOs better address old research questions or develop new research questions:\n",
    "\n",
    " 1. New data sources to consider:\n",
    "       * APIs and Webscraping\n",
    "\n",
    "\n",
    " 2. Data Science Methods\n",
    "       * Natural Language Processing\n",
    "       * Machine Learning\n",
    "       \n",
    "Demo using SIOP-related Tweets:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![alt text](https://github.com/TNT-Lab/SIOP-2019-IO-Data-Science-Master-Tutorial/blob/master/notebookpictures/intropicture.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## New Data Sources (APIs & Webscraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### APIs and Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Two primary ways of systematically accessing information from the web:\n",
    "\n",
    "**(Manual) Web Scraping: requires crawling webpages for HTML tags**\n",
    "* generally used when an API is not available\n",
    "* usually generates unstructured/messy output\n",
    "* see https://rlanders.net/scrapy/ for step-by-step walk through\n",
    "\n",
    "**Application Programming Interfaces (APIs): a gateway into a system created by a service provider**\n",
    "* Almost universally intended and designed for real-time access by other websites, but you can use them too \n",
    "* Requires learning API documentation – they’re all different\n",
    "* Most APIs require “keys” or “tokens” or “secret phrase”, etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll demo a user-friendly way of accessing the Twitter API using R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing Twitter's API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the libraries we'll need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'rtweet' was built under R version 3.5.3\"\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(rtweet)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set up access to the Twitter API. The Twitter API will allow us to request data from Twitter to use later in our analyses. In order to obtain permission to access the Twitter API, you'll need to first set up credentials. \n",
    "\n",
    "To do this, you'll need to log into Twitter and create an application: https://developer.twitter.com/en/account/get-started. \n",
    "\n",
    "Once you have created an application, locate your \"keys and tokens.\" We'll temporarily save these to our local R environment. Make sure you don't share these with others!\n",
    "\n",
    "Add keys here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these with your Twitter access keys (in the quote) - DO NOT SHARE YOUR KEYS WITH OTHERS\n",
    "appname <- \"SIOP Data Science Tutorial\"\n",
    "key <- \"\"\n",
    "secret <- \"\"\n",
    "access_token <- \"\"\n",
    "access_secret <- \"\"\n",
    "\t\n",
    "# Store these keys for the next step (just run this script)\n",
    "twitter_token<- create_token(\n",
    "  app = appname,\n",
    "  consumer_key = key,\n",
    "  consumer_secret = secret,\n",
    "  access_token = access_token,\n",
    "  access_secret =access_secret)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our Twitter API credential set up, we can submit an API request. To do this we will use the R package **rtweet** (https://rtweet.info/). Using this package you can interact with Twitter's API by searching recent tweets by keywords, publishing tweets, getting trends, and even pulling entire timelines. For this demonstration, we'll be searching for tweets related to SIOP and IO psychology by searching for tweets that contain #SIOP, #IOPsych, #IamSIOP, #SIOP19. \n",
    "\n",
    "It's important to note that free access to Twitter's API restricts search capabilities to tweets that have occurred in the past 6-9 days. Twitter also limits search results to 18,000 tweets every 15 minutes. Paid tiers provide more access and options. \n",
    "\n",
    "Using the **rtweets::search_tweets()**  we'll specify our search parameters using the _q_ argument and the number of tweets using the _n_ argument. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching for tweets...\n",
      "Warning message:\n",
      "\"215 - Bad Authentication data.\"Warning message:\n",
      "\"Bad Authentication data.\"Finished collecting tweets!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "<0 x 0 matrix>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#request \n",
    "siop_tweets <- search_tweets(q = \"#SIOP OR #IOPsych OR #IamSIOP OR #SIOP19\",\n",
    "                              n = 3000)\n",
    "\n",
    "nrow(siop_tweets)\n",
    "head(siop_tweets, n = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4349"
      ],
      "text/latex": [
       "4349"
      ],
      "text/markdown": [
       "4349"
      ],
      "text/plain": [
       "[1] 4349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#if we want to save our tweets, we can use the save_as_csv function\n",
    "#save_as_csv(siop_tweets, \"tweets.csv\")\n",
    "#write.csv doesn't work here because of the structure of the searh_tweets output\n",
    "\n",
    "#for this demonstration, we'll just read in our saved tweets (These tweets were collected over the span of three weeks by running the above function once/week)\n",
    "tweets <- read.csv(\"tweets.csv\")\n",
    "nrow(tweets) #we have about 4k SIOP-related tweets to work with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have some data! Let's glance at it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>user_id</th><th scope=col>status_id</th><th scope=col>created_at</th><th scope=col>screen_name</th><th scope=col>text</th><th scope=col>source</th><th scope=col>display_text_width</th><th scope=col>reply_to_status_id</th><th scope=col>reply_to_user_id</th><th scope=col>reply_to_screen_name</th><th scope=col>...</th><th scope=col>statuses_count</th><th scope=col>favourites_count</th><th scope=col>account_created_at</th><th scope=col>verified</th><th scope=col>profile_url</th><th scope=col>profile_expanded_url</th><th scope=col>account_lang</th><th scope=col>profile_banner_url</th><th scope=col>profile_background_url</th><th scope=col>profile_image_url</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>4347</th><td>x838107058633310210                                                                                                                                                           </td><td>x1108099467419570177                                                                                                                                                          </td><td>3/19/2019 20:14                                                                                                                                                               </td><td>LeboSebete                                                                                                                                                                    </td><td>AARP says IO psychology is the best second career for people over 40. I think it is the best career for people under 40 too! See the article #iopsych\n",
       "https://t.co/8uvl6B1w7C</td><td>Twitter for iPhone                                                                                                                                                            </td><td>140                                                                                                                                                                           </td><td>                                                                                                                                                                              </td><td>                                                                                                                                                                              </td><td>                                                                                                                                                                              </td><td>...                                                                                                                                                                           </td><td>2744                                                                                                                                                                          </td><td>11379                                                                                                                                                                         </td><td>3/4/2017 19:21                                                                                                                                                                </td><td>FALSE                                                                                                                                                                         </td><td>https://t.co/2FMT3011MB                                                                                                                                                       </td><td>http://Instagram.com/just_Lebo_13                                                                                                                                             </td><td>en                                                                                                                                                                            </td><td>https://pbs.twimg.com/profile_banners/838107058633310210/1508830450                                                                                                           </td><td>                                                                                                                                                                              </td><td>http://pbs.twimg.com/profile_images/1023327586754211840/TPzGtRR3_normal.jpg                                                                                                   </td></tr>\n",
       "\t<tr><th scope=row>4348</th><td>x773345434605613056                                                                                                                                                           </td><td>x1108094703952711680                                                                                                                                                          </td><td>3/19/2019 19:55                                                                                                                                                               </td><td>jcolosimo_dci                                                                                                                                                                 </td><td>#SIOP https://t.co/TeSiAeyFTJ                                                                                                                                                 </td><td>Twitter Web Client                                                                                                                                                            </td><td>  5                                                                                                                                                                           </td><td>                                                                                                                                                                              </td><td>                                                                                                                                                                              </td><td>                                                                                                                                                                              </td><td>...                                                                                                                                                                           </td><td>  59                                                                                                                                                                          </td><td>   44                                                                                                                                                                         </td><td>9/7/2016 2:21                                                                                                                                                                 </td><td>FALSE                                                                                                                                                                         </td><td>                                                                                                                                                                              </td><td>                                                                                                                                                                              </td><td>en                                                                                                                                                                            </td><td>                                                                                                                                                                              </td><td>                                                                                                                                                                              </td><td>http://pbs.twimg.com/profile_images/1004832985227677697/Cre1Ld1f_normal.jpg                                                                                                   </td></tr>\n",
       "\t<tr><th scope=row>4349</th><td>x362743713                                                                                                                                                                    </td><td>x1108073879443030016                                                                                                                                                          </td><td>3/19/2019 18:32                                                                                                                                                               </td><td>anfmathgr6                                                                                                                                                                    </td><td>Useful list. #SIOP #Ellchat_BkClub https://t.co/jDZheeBEJI                                                                                                                    </td><td>Twitter for iPhone                                                                                                                                                            </td><td> 79                                                                                                                                                                           </td><td>                                                                                                                                                                              </td><td>                                                                                                                                                                              </td><td>                                                                                                                                                                              </td><td>...                                                                                                                                                                           </td><td> 362                                                                                                                                                                          </td><td>  525                                                                                                                                                                         </td><td>8/26/2011 22:33                                                                                                                                                               </td><td>FALSE                                                                                                                                                                         </td><td>https://t.co/asjK4A9144                                                                                                                                                       </td><td>http://middleschoolmysteries.blogspot.com                                                                                                                                     </td><td>en                                                                                                                                                                            </td><td>https://pbs.twimg.com/profile_banners/362743713/1498168208                                                                                                                    </td><td>http://abs.twimg.com/images/themes/theme10/bg.gif                                                                                                                             </td><td>http://pbs.twimg.com/profile_images/966806188397490176/bfsA_9zG_normal.jpg                                                                                                    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "  & user\\_id & status\\_id & created\\_at & screen\\_name & text & source & display\\_text\\_width & reply\\_to\\_status\\_id & reply\\_to\\_user\\_id & reply\\_to\\_screen\\_name & ... & statuses\\_count & favourites\\_count & account\\_created\\_at & verified & profile\\_url & profile\\_expanded\\_url & account\\_lang & profile\\_banner\\_url & profile\\_background\\_url & profile\\_image\\_url\\\\\n",
       "\\hline\n",
       "\t4347 & x838107058633310210                                                                                                                                                              & x1108099467419570177                                                                                                                                                             & 3/19/2019 20:14                                                                                                                                                                  & LeboSebete                                                                                                                                                                       & AARP says IO psychology is the best second career for people over 40. I think it is the best career for people under 40 too! See the article \\#iopsych\n",
       "https://t.co/8uvl6B1w7C & Twitter for iPhone                                                                                                                                                               & 140                                                                                                                                                                              &                                                                                                                                                                                  &                                                                                                                                                                                  &                                                                                                                                                                                  & ...                                                                                                                                                                              & 2744                                                                                                                                                                             & 11379                                                                                                                                                                            & 3/4/2017 19:21                                                                                                                                                                   & FALSE                                                                                                                                                                            & https://t.co/2FMT3011MB                                                                                                                                                          & http://Instagram.com/just\\_Lebo\\_13                                                                                                                                            & en                                                                                                                                                                               & https://pbs.twimg.com/profile\\_banners/838107058633310210/1508830450                                                                                                            &                                                                                                                                                                                  & http://pbs.twimg.com/profile\\_images/1023327586754211840/TPzGtRR3\\_normal.jpg                                                                                                 \\\\\n",
       "\t4348 & x773345434605613056                                                                                                                                                              & x1108094703952711680                                                                                                                                                             & 3/19/2019 19:55                                                                                                                                                                  & jcolosimo\\_dci                                                                                                                                                                  & \\#SIOP https://t.co/TeSiAeyFTJ                                                                                                                                                  & Twitter Web Client                                                                                                                                                               &   5                                                                                                                                                                              &                                                                                                                                                                                  &                                                                                                                                                                                  &                                                                                                                                                                                  & ...                                                                                                                                                                              &   59                                                                                                                                                                             &    44                                                                                                                                                                            & 9/7/2016 2:21                                                                                                                                                                    & FALSE                                                                                                                                                                            &                                                                                                                                                                                  &                                                                                                                                                                                  & en                                                                                                                                                                               &                                                                                                                                                                                  &                                                                                                                                                                                  & http://pbs.twimg.com/profile\\_images/1004832985227677697/Cre1Ld1f\\_normal.jpg                                                                                                 \\\\\n",
       "\t4349 & x362743713                                                                                                                                                                           & x1108073879443030016                                                                                                                                                                 & 3/19/2019 18:32                                                                                                                                                                      & anfmathgr6                                                                                                                                                                           & Useful list. \\#SIOP \\#Ellchat\\_BkClub https://t.co/jDZheeBEJI                                                                                                                     & Twitter for iPhone                                                                                                                                                                   &  79                                                                                                                                                                                  &                                                                                                                                                                                      &                                                                                                                                                                                      &                                                                                                                                                                                      & ...                                                                                                                                                                                  &  362                                                                                                                                                                                 &   525                                                                                                                                                                                & 8/26/2011 22:33                                                                                                                                                                      & FALSE                                                                                                                                                                                & https://t.co/asjK4A9144                                                                                                                                                              & http://middleschoolmysteries.blogspot.com                                                                                                                                            & en                                                                                                                                                                                   & https://pbs.twimg.com/profile\\_banners/362743713/1498168208                                                                                                                         & http://abs.twimg.com/images/themes/theme10/bg.gif                                                                                                                                    & http://pbs.twimg.com/profile\\_images/966806188397490176/bfsA\\_9zG\\_normal.jpg                                                                                                    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | user_id | status_id | created_at | screen_name | text | source | display_text_width | reply_to_status_id | reply_to_user_id | reply_to_screen_name | ... | statuses_count | favourites_count | account_created_at | verified | profile_url | profile_expanded_url | account_lang | profile_banner_url | profile_background_url | profile_image_url |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 4347 | x838107058633310210                                                                                                                                                            | x1108099467419570177                                                                                                                                                           | 3/19/2019 20:14                                                                                                                                                                | LeboSebete                                                                                                                                                                     | AARP says IO psychology is the best second career for people over 40. I think it is the best career for people under 40 too! See the article #iopsych\n",
       "https://t.co/8uvl6B1w7C | Twitter for iPhone                                                                                                                                                             | 140                                                                                                                                                                            |                                                                                                                                                                                |                                                                                                                                                                                |                                                                                                                                                                                | ...                                                                                                                                                                            | 2744                                                                                                                                                                           | 11379                                                                                                                                                                          | 3/4/2017 19:21                                                                                                                                                                 | FALSE                                                                                                                                                                          | https://t.co/2FMT3011MB                                                                                                                                                        | http://Instagram.com/just_Lebo_13                                                                                                                                              | en                                                                                                                                                                             | https://pbs.twimg.com/profile_banners/838107058633310210/1508830450                                                                                                            |                                                                                                                                                                                | http://pbs.twimg.com/profile_images/1023327586754211840/TPzGtRR3_normal.jpg                                                                                                    |\n",
       "| 4348 | x773345434605613056                                                                                                                                                            | x1108094703952711680                                                                                                                                                           | 3/19/2019 19:55                                                                                                                                                                | jcolosimo_dci                                                                                                                                                                  | #SIOP https://t.co/TeSiAeyFTJ                                                                                                                                                  | Twitter Web Client                                                                                                                                                             |   5                                                                                                                                                                            |                                                                                                                                                                                |                                                                                                                                                                                |                                                                                                                                                                                | ...                                                                                                                                                                            |   59                                                                                                                                                                           |    44                                                                                                                                                                          | 9/7/2016 2:21                                                                                                                                                                  | FALSE                                                                                                                                                                          |                                                                                                                                                                                |                                                                                                                                                                                | en                                                                                                                                                                             |                                                                                                                                                                                |                                                                                                                                                                                | http://pbs.twimg.com/profile_images/1004832985227677697/Cre1Ld1f_normal.jpg                                                                                                    |\n",
       "| 4349 | x362743713                                                                                                                                                                     | x1108073879443030016                                                                                                                                                           | 3/19/2019 18:32                                                                                                                                                                | anfmathgr6                                                                                                                                                                     | Useful list. #SIOP #Ellchat_BkClub https://t.co/jDZheeBEJI                                                                                                                     | Twitter for iPhone                                                                                                                                                             |  79                                                                                                                                                                            |                                                                                                                                                                                |                                                                                                                                                                                |                                                                                                                                                                                | ...                                                                                                                                                                            |  362                                                                                                                                                                           |   525                                                                                                                                                                          | 8/26/2011 22:33                                                                                                                                                                | FALSE                                                                                                                                                                          | https://t.co/asjK4A9144                                                                                                                                                        | http://middleschoolmysteries.blogspot.com                                                                                                                                      | en                                                                                                                                                                             | https://pbs.twimg.com/profile_banners/362743713/1498168208                                                                                                                     | http://abs.twimg.com/images/themes/theme10/bg.gif                                                                                                                              | http://pbs.twimg.com/profile_images/966806188397490176/bfsA_9zG_normal.jpg                                                                                                     |\n",
       "\n"
      ],
      "text/plain": [
       "     user_id             status_id            created_at      screen_name  \n",
       "4347 x838107058633310210 x1108099467419570177 3/19/2019 20:14 LeboSebete   \n",
       "4348 x773345434605613056 x1108094703952711680 3/19/2019 19:55 jcolosimo_dci\n",
       "4349 x362743713          x1108073879443030016 3/19/2019 18:32 anfmathgr6   \n",
       "     text                                                                                                                                                                          \n",
       "4347 AARP says IO psychology is the best second career for people over 40. I think it is the best career for people under 40 too! See the article #iopsych\\nhttps://t.co/8uvl6B1w7C\n",
       "4348 #SIOP https://t.co/TeSiAeyFTJ                                                                                                                                                 \n",
       "4349 Useful list. #SIOP #Ellchat_BkClub https://t.co/jDZheeBEJI                                                                                                                    \n",
       "     source             display_text_width reply_to_status_id reply_to_user_id\n",
       "4347 Twitter for iPhone 140                                                   \n",
       "4348 Twitter Web Client   5                                                   \n",
       "4349 Twitter for iPhone  79                                                   \n",
       "     reply_to_screen_name ... statuses_count favourites_count\n",
       "4347                      ... 2744           11379           \n",
       "4348                      ...   59              44           \n",
       "4349                      ...  362             525           \n",
       "     account_created_at verified profile_url            \n",
       "4347 3/4/2017 19:21     FALSE    https://t.co/2FMT3011MB\n",
       "4348 9/7/2016 2:21      FALSE                           \n",
       "4349 8/26/2011 22:33    FALSE    https://t.co/asjK4A9144\n",
       "     profile_expanded_url                      account_lang\n",
       "4347 http://Instagram.com/just_Lebo_13         en          \n",
       "4348                                           en          \n",
       "4349 http://middleschoolmysteries.blogspot.com en          \n",
       "     profile_banner_url                                                 \n",
       "4347 https://pbs.twimg.com/profile_banners/838107058633310210/1508830450\n",
       "4348                                                                    \n",
       "4349 https://pbs.twimg.com/profile_banners/362743713/1498168208         \n",
       "     profile_background_url                           \n",
       "4347                                                  \n",
       "4348                                                  \n",
       "4349 http://abs.twimg.com/images/themes/theme10/bg.gif\n",
       "     profile_image_url                                                          \n",
       "4347 http://pbs.twimg.com/profile_images/1023327586754211840/TPzGtRR3_normal.jpg\n",
       "4348 http://pbs.twimg.com/profile_images/1004832985227677697/Cre1Ld1f_normal.jpg\n",
       "4349 http://pbs.twimg.com/profile_images/966806188397490176/bfsA_9zG_normal.jpg "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(tweets, n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty clean output but we'll still need to do some data cleaning depending on which parts of the data we're interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional things to consider\n",
    "* all data sources have limitations\n",
    "* psychometrics still matter\n",
    "* privacy & ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Methods (Natural Language Processing and Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common characteristics of these approaches\n",
    "* Not all that different from traditional approaches (e.g., OLS Regression, content coding)\n",
    "* Tend to prioritize prediction over explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP is the use of algorithms to create meaning from text data\n",
    "\n",
    "The goal is to convert text into numbers in a meaningful way. But, there are an infinite number of ways to do this.\n",
    "\n",
    "Common approaches:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/TNT-Lab/SIOP-2019-IO-Data-Science-Master-Tutorial/blob/master/notebookpictures/NLPpicture2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/TNT-Lab/SIOP-2019-IO-Data-Science-Master-Tutorial/blob/master/notebookpictures/NLPpicture.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demo, we'll clean up some of the tweet text and display common words in a word cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again load the R libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tm' was built under R version 3.5.2\"Loading required package: NLP\n",
      "Warning message:\n",
      "\"package 'NLP' was built under R version 3.5.2\"Warning message:\n",
      "\"package 'wordcloud' was built under R version 3.5.2\"Loading required package: RColorBrewer\n"
     ]
    }
   ],
   "source": [
    "library(stringr)\n",
    "library(tm)\n",
    "library(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first filter out some tweets that aren't useful to us (retweets and SIOP model-related tweets)\n",
    "\n",
    "**note that only retweets without added text are removed, so we'll keep the ones with commentary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Let's specify that the tweet is in English & try to exclude some SIOPModel -related tweets\n",
    "tweets <- tweets %>%\n",
    "dplyr::filter(lang == \"en\") %>%\n",
    "dplyr::filter( !grepl('siopmodel', text))%>%\n",
    "dplyr::filter( !grepl('ellchat', text))\n",
    "\n",
    "#let's also remove retweets\n",
    "tweets_preprocessed <- tweets%>%\n",
    "dplyr::filter(is_retweet == FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the twitter text prior to pre-processing (a random sample of the dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>text</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>659</th><td>@twbriggs Amazon is hiring plenty of I/Os, too!  #IOPsych                                                                                                                                                                                                                                 </td></tr>\n",
       "\t<tr><th scope=row>134</th><td>Amazon gets an edge with its secret squad of PhD economists  #iopsych #datascience https://t.co/bGXnoE4vrs                                                                                                                                                                                </td></tr>\n",
       "\t<tr><th scope=row>179</th><td>Thank you @glintinc and @UltimateHCM for being #SIOP19 Diamond Partners! âœ¨ Register for the annual conference today!:  https://t.co/qNUomvYTbK #TeamSIOP https://t.co/CSad30z1GK                                                                                                        </td></tr>\n",
       "\t<tr><th scope=row>792</th><td>Managers Need to Recognize When Employees are Giving Too Much https://t.co/Z3I9MCNdrM #IOPsych                                                                                                                                                                                            </td></tr>\n",
       "\t<tr><th scope=row>155</th><td>Thousands of #IOPsych pros will share insights on the most important topics of the day at #SIOP19, April 4-6. Where will you be? Attendance is open to all. Read more about conference sessions related to the #Top10WorkplaceTrends here: https://t.co/wQpgQ1liIx https://t.co/XJTj0gGiev</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & text\\\\\n",
       "\\hline\n",
       "\t659 & @twbriggs Amazon is hiring plenty of I/Os, too!  \\#IOPsych                                                                                                                                                                                                                                 \\\\\n",
       "\t134 & Amazon gets an edge with its secret squad of PhD economists  \\#iopsych \\#datascience https://t.co/bGXnoE4vrs                                                                                                                                                                                \\\\\n",
       "\t179 & Thank you @glintinc and @UltimateHCM for being \\#SIOP19 Diamond Partners! âœ¨ Register for the annual conference today!:  https://t.co/qNUomvYTbK \\#TeamSIOP https://t.co/CSad30z1GK                                                                                                        \\\\\n",
       "\t792 & Managers Need to Recognize When Employees are Giving Too Much https://t.co/Z3I9MCNdrM \\#IOPsych                                                                                                                                                                                            \\\\\n",
       "\t155 & Thousands of \\#IOPsych pros will share insights on the most important topics of the day at \\#SIOP19, April 4-6. Where will you be? Attendance is open to all. Read more about conference sessions related to the \\#Top10WorkplaceTrends here: https://t.co/wQpgQ1liIx https://t.co/XJTj0gGiev\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | text |\n",
       "|---|---|\n",
       "| 659 | @twbriggs Amazon is hiring plenty of I/Os, too!  #IOPsych                                                                                                                                                                                                                                  |\n",
       "| 134 | Amazon gets an edge with its secret squad of PhD economists  #iopsych #datascience https://t.co/bGXnoE4vrs                                                                                                                                                                                 |\n",
       "| 179 | Thank you @glintinc and @UltimateHCM for being #SIOP19 Diamond Partners! âœ¨ Register for the annual conference today!:  https://t.co/qNUomvYTbK #TeamSIOP https://t.co/CSad30z1GK                                                                                                         |\n",
       "| 792 | Managers Need to Recognize When Employees are Giving Too Much https://t.co/Z3I9MCNdrM #IOPsych                                                                                                                                                                                             |\n",
       "| 155 | Thousands of #IOPsych pros will share insights on the most important topics of the day at #SIOP19, April 4-6. Where will you be? Attendance is open to all. Read more about conference sessions related to the #Top10WorkplaceTrends here: https://t.co/wQpgQ1liIx https://t.co/XJTj0gGiev |\n",
       "\n"
      ],
      "text/plain": [
       "    text                                                                                                                                                                                                                                                                                      \n",
       "659 @twbriggs Amazon is hiring plenty of I/Os, too!  #IOPsych                                                                                                                                                                                                                                 \n",
       "134 Amazon gets an edge with its secret squad of PhD economists  #iopsych #datascience https://t.co/bGXnoE4vrs                                                                                                                                                                                \n",
       "179 Thank you @glintinc and @UltimateHCM for being #SIOP19 Diamond Partners! âœ¨ Register for the annual conference today!:  https://t.co/qNUomvYTbK #TeamSIOP https://t.co/CSad30z1GK                                                                                                        \n",
       "792 Managers Need to Recognize When Employees are Giving Too Much https://t.co/Z3I9MCNdrM #IOPsych                                                                                                                                                                                            \n",
       "155 Thousands of #IOPsych pros will share insights on the most important topics of the day at #SIOP19, April 4-6. Where will you be? Attendance is open to all. Read more about conference sessions related to the #Top10WorkplaceTrends here: https://t.co/wQpgQ1liIx https://t.co/XJTj0gGiev"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_preprocessed %>%\n",
    "mutate(text = as.character(text))%>%\n",
    "select(text)%>%\n",
    "sample_n(size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to do some preprocessing. We'll remove URLs, retweets, hashtags, mentions, special characters, punctuation, and stopwords. We'll also remove the search terms we used.\n",
    "\n",
    "We'll also strip white space, and convert to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess tweet test\n",
    "tweets_preprocessed$text <- lapply(tweets_preprocessed$text, function(x) {\n",
    "\n",
    "  x = gsub('http\\\\S+\\\\s*', '', x) # Remove URLs\n",
    "  x = gsub('[[:punct:]]', '', x) # Remove Punctuations\n",
    "  x =  iconv(x,from=\"UTF-8\",to=\"ASCII//TRANSLIT\") # remove accents\n",
    "  x = gsub('\\\\b+RT', '', x) # Remove RT\n",
    "  x = gsub('#\\\\S+', '', x) # Remove Hashtags\n",
    "  x = gsub('@\\\\S+', '', x) # Remove Mentions\n",
    "  x = gsub('[[:cntrl:]]', '', x) # Remove Controls and special characters\n",
    "  x = str_to_lower(x) # convert to lowercase\n",
    "  x = removeWords(x, stopwords(\"en\")) # remove stopwords\n",
    "  x = removeWords(x, c(\"siop\",\"iopsych\",\"iamsiop\",\"siop19\")) # remove search terms\n",
    "  x = removeWords(x, c(\"amp\")) # remove \"amp\" associated with & and other words that are not meaningful in this context\n",
    "  x = gsub(' +',' ',x) # Remove extra whitespaces\n",
    "  \n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-examine the text after preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>text</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>921</th><td> can feel endofsemester panic just around corner excited come spring summer first present poster msc thesis two weeks sioptweets u0001f973</td></tr>\n",
       "\t<tr><th scope=row>274</th><td>crestwood elementary staff learned thai today learn feels english learner classroom know language                                         </td></tr>\n",
       "\t<tr><th scope=row>761</th><td> talentmetrics managers need recognize employees giving much                                                                              </td></tr>\n",
       "\t<tr><th scope=row>160</th><td>start career placement center stop upload resumes post job openings network candidates organizations teamsiop                             </td></tr>\n",
       "\t<tr><th scope=row>301</th><td>beneubanks hey beneubanks connect orgvitality speak jeffreysaltzman tops field                                                            </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & text\\\\\n",
       "\\hline\n",
       "\t921 &  can feel endofsemester panic just around corner excited come spring summer first present poster msc thesis two weeks sioptweets u0001f973\\\\\n",
       "\t274 & crestwood elementary staff learned thai today learn feels english learner classroom know language                                         \\\\\n",
       "\t761 &  talentmetrics managers need recognize employees giving much                                                                              \\\\\n",
       "\t160 & start career placement center stop upload resumes post job openings network candidates organizations teamsiop                             \\\\\n",
       "\t301 & beneubanks hey beneubanks connect orgvitality speak jeffreysaltzman tops field                                                            \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | text |\n",
       "|---|---|\n",
       "| 921 |  can feel endofsemester panic just around corner excited come spring summer first present poster msc thesis two weeks sioptweets u0001f973 |\n",
       "| 274 | crestwood elementary staff learned thai today learn feels english learner classroom know language                                          |\n",
       "| 761 |  talentmetrics managers need recognize employees giving much                                                                               |\n",
       "| 160 | start career placement center stop upload resumes post job openings network candidates organizations teamsiop                              |\n",
       "| 301 | beneubanks hey beneubanks connect orgvitality speak jeffreysaltzman tops field                                                             |\n",
       "\n"
      ],
      "text/plain": [
       "    text                                                                                                                                      \n",
       "921  can feel endofsemester panic just around corner excited come spring summer first present poster msc thesis two weeks sioptweets u0001f973\n",
       "274 crestwood elementary staff learned thai today learn feels english learner classroom know language                                         \n",
       "761  talentmetrics managers need recognize employees giving much                                                                              \n",
       "160 start career placement center stop upload resumes post job openings network candidates organizations teamsiop                             \n",
       "301 beneubanks hey beneubanks connect orgvitality speak jeffreysaltzman tops field                                                            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_preprocessed %>%\n",
    "mutate(text = as.character(text))%>%\n",
    "select(text)%>%\n",
    "sample_n(size = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a corpus and convert our text into a document term matrix (rows are tweets, columns are n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>2019</th><th scope=col>academic</th><th scope=col>also</th><th scope=col>analytics</th><th scope=col>annual</th><th scope=col>another</th><th scope=col>app</th><th scope=col>april</th><th scope=col>article</th><th scope=col>attend</th><th scope=col>...</th><th scope=col>washington</th><th scope=col>way</th><th scope=col>week</th><th scope=col>well</th><th scope=col>will</th><th scope=col>work</th><th scope=col>workplace</th><th scope=col>year</th><th scope=col>years</th><th scope=col>youll</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>2  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " 2019 & academic & also & analytics & annual & another & app & april & article & attend & ... & washington & way & week & well & will & work & workplace & year & years & youll\\\\\n",
       "\\hline\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 1   & 0   & 0   & 0  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 1   & 0   & 0   & 0   & 2   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 2019 | academic | also | analytics | annual | another | app | april | article | attend | ... | washington | way | week | well | will | work | workplace | year | years | youll |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   |\n",
       "| 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   | 2   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "\n"
      ],
      "text/plain": [
       "  2019 academic also analytics annual another app april article attend ...\n",
       "1 0    0        0    0         0      0       0   0     0       0      ...\n",
       "2 0    0        0    0         0      0       0   0     0       0      ...\n",
       "3 0    0        0    0         0      0       0   0     0       0      ...\n",
       "4 0    0        0    0         0      0       0   0     0       0      ...\n",
       "5 0    0        0    0         0      1       0   0     0       2      ...\n",
       "6 0    0        0    0         0      0       0   0     0       0      ...\n",
       "  washington way week well will work workplace year years youll\n",
       "1 0          0   0    0    0    0    0         0    0     0    \n",
       "2 0          0   0    0    0    0    0         0    0     0    \n",
       "3 0          0   0    0    0    0    0         0    0     0    \n",
       "4 0          0   0    0    0    0    1         0    0     0    \n",
       "5 0          0   0    0    0    0    0         0    0     0    \n",
       "6 0          0   0    0    0    0    0         0    0     0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_corpus <- VCorpus(VectorSource(tweets_preprocessed$text))# Convert to corpus (structured set of texts)\n",
    "\n",
    "tweets_dtm <- DocumentTermMatrix(tweets_corpus) #create a document-term-matrix\n",
    "\n",
    "tweets_dtm <- removeSparseTerms(tweets_dtm, 0.99) # We'll also get rid of relatively unusual terms\n",
    "\n",
    "DTM_df <- as.data.frame(as.matrix(tweets_dtm)) #finally let's convert the dtm into a dataframe\n",
    "\n",
    "head(DTM_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our tweet text is clean, let's start to look the text a bit. We can visualize common words with a simple wordcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAALQCAMAAACOibeuAAABI1BMVEVmZmZmeWRml1Bmojtm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\nEiy2AgkJVeL/B1XulW9lkRMFAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordCounts <- colSums(DTM_df) #create word counts\n",
    "\n",
    "wordNames <- names(DTM_df) #label word counts with word name\n",
    "\n",
    "options(repr.plot.width=6, repr.plot.height=6) #resize word cloud\n",
    "\n",
    "wordcloud(wordNames, wordCounts, max.words=30,, colors = brewer.pal(8, \"Dark2\")) #create word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the a list of the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting by wordCounts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>wordNames</th><th scope=col>wordCounts</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>conference   </td><td>93           </td></tr>\n",
       "\t<tr><td>work         </td><td>88           </td></tr>\n",
       "\t<tr><td>will         </td><td>86           </td></tr>\n",
       "\t<tr><td>sioptweets   </td><td>78           </td></tr>\n",
       "\t<tr><td>can          </td><td>74           </td></tr>\n",
       "\t<tr><td>new          </td><td>72           </td></tr>\n",
       "\t<tr><td>talentmetrics</td><td>72           </td></tr>\n",
       "\t<tr><td>psychology   </td><td>71           </td></tr>\n",
       "\t<tr><td>learn        </td><td>67           </td></tr>\n",
       "\t<tr><td>people       </td><td>63           </td></tr>\n",
       "\t<tr><td>research     </td><td>63           </td></tr>\n",
       "\t<tr><td>april        </td><td>62           </td></tr>\n",
       "\t<tr><td>hrtribe      </td><td>58           </td></tr>\n",
       "\t<tr><td>get          </td><td>57           </td></tr>\n",
       "\t<tr><td>students     </td><td>55           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " wordNames & wordCounts\\\\\n",
       "\\hline\n",
       "\t conference    & 93           \\\\\n",
       "\t work          & 88           \\\\\n",
       "\t will          & 86           \\\\\n",
       "\t sioptweets    & 78           \\\\\n",
       "\t can           & 74           \\\\\n",
       "\t new           & 72           \\\\\n",
       "\t talentmetrics & 72           \\\\\n",
       "\t psychology    & 71           \\\\\n",
       "\t learn         & 67           \\\\\n",
       "\t people        & 63           \\\\\n",
       "\t research      & 63           \\\\\n",
       "\t april         & 62           \\\\\n",
       "\t hrtribe       & 58           \\\\\n",
       "\t get           & 57           \\\\\n",
       "\t students      & 55           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| wordNames | wordCounts |\n",
       "|---|---|\n",
       "| conference    | 93            |\n",
       "| work          | 88            |\n",
       "| will          | 86            |\n",
       "| sioptweets    | 78            |\n",
       "| can           | 74            |\n",
       "| new           | 72            |\n",
       "| talentmetrics | 72            |\n",
       "| psychology    | 71            |\n",
       "| learn         | 67            |\n",
       "| people        | 63            |\n",
       "| research      | 63            |\n",
       "| april         | 62            |\n",
       "| hrtribe       | 58            |\n",
       "| get           | 57            |\n",
       "| students      | 55            |\n",
       "\n"
      ],
      "text/plain": [
       "   wordNames     wordCounts\n",
       "1  conference    93        \n",
       "2  work          88        \n",
       "3  will          86        \n",
       "4  sioptweets    78        \n",
       "5  can           74        \n",
       "6  new           72        \n",
       "7  talentmetrics 72        \n",
       "8  psychology    71        \n",
       "9  learn         67        \n",
       "10 people        63        \n",
       "11 research      63        \n",
       "12 april         62        \n",
       "13 hrtribe       58        \n",
       "14 get           57        \n",
       "15 students      55        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tibble(wordNames, wordCounts) %>% arrange(desc(wordCounts)) %>% top_n(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ML algorithm refers to a computer program that learns from data to generate predictions. Machine learning isn't all that different from our normal modeling approaches (think OLS linear regression), but machine learning typically has a different goal.\n",
    "\n",
    "Traditionally, our **traditional analyses** are focused on _\"given this theory, how well do the data describe y?\"_ \n",
    "* The primary goal is interpretability of regression coefficients and ultimately draw conclusions about our predictors\n",
    "\n",
    "In contrast, **machine learning** is focused on _\"given this data, what algorithm and features will best predict y in other datasets?\"_ \n",
    "* The primary goal is generalizable prediction, typically at the cost of  interpretability of coefficients. \n",
    "* Machine learning explicitly addresses the bias-variance trade-off, which optimizes model complexity such that we are not overfitting to one dataset but also so that we're maximizing prediction. \n",
    "\n",
    "There a few types of machine learning: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![alt text](https://github.com/TNT-Lab/SIOP-2019-IO-Data-Science-Master-Tutorial/blob/master/notebookpictures/MLpicture.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also quite a few decision points:\n",
    "* model selection (random forest, support vector machines, elastic net)\n",
    "* parameter selection (variables and parameter estimation)\n",
    "* hyperparameter selection (configuration options for each model) \n",
    "\n",
    "Typically you make these decision (or the algorithm does for you) empirically. In other words, many of these decisions are made based on out of sample model performance. \n",
    "\n",
    "Finally, there are a few key situations in which machine learning models are particularly useful (Putka, Beatty & Reeder, 2017):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![alt text](https://github.com/TNT-Lab/SIOP-2019-IO-Data-Science-Master-Tutorial/blob/master/notebookpictures/MLpicture2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested in learning more about using machine learning in IO, I would recommend this paper:\n",
    "\n",
    "Putka, D. J., Beatty, A. S., & Reeder, M. C. (2018). Modern prediction methods: New perspectives on a common problem. _Organizational Research Methods, 21_(3), 689-732.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now back to our tweets. Say we want to predict retweets and favorite counts by the words used in a tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's load our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.5.2\"Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Attaching package: 'ggplot2'\n",
      "\n",
      "The following object is masked from 'package:NLP':\n",
      "\n",
      "    annotate\n",
      "\n",
      "Loading required package: Matrix\n",
      "Loading required package: foreach\n",
      "Loaded glmnet 2.0-16\n",
      "\n",
      "Warning message:\n",
      "\"package 'gbm' was built under R version 3.5.2\"Loaded gbm 2.1.5\n",
      "Warning message:\n",
      "\"package 'kernlab' was built under R version 3.5.2\"\n",
      "Attaching package: 'kernlab'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    alpha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "library(glmnet)\n",
    "library(gbm)\n",
    "library(kernlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a bit of data cleaning first.\n",
    "\n",
    "We'll operationalize **\"tweet popularity\"** as a composite of favorites and likes per tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ID</th><th scope=col>tweet_popularity</th><th scope=col>2019</th><th scope=col>academic</th><th scope=col>also</th><th scope=col>analytics</th><th scope=col>annual</th><th scope=col>another</th><th scope=col>app</th><th scope=col>april</th><th scope=col>...</th><th scope=col>washington</th><th scope=col>way</th><th scope=col>week</th><th scope=col>well</th><th scope=col>will</th><th scope=col>work</th><th scope=col>workplace</th><th scope=col>year</th><th scope=col>years</th><th scope=col>youll</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1  </td><td>106</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>2  </td><td>105</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>3  </td><td> 98</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>4  </td><td> 87</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>5  </td><td> 92</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>6  </td><td> 78</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " ID & tweet\\_popularity & 2019 & academic & also & analytics & annual & another & app & april & ... & washington & way & week & well & will & work & workplace & year & years & youll\\\\\n",
       "\\hline\n",
       "\t 1   & 106 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 2   & 105 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 3   &  98 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 4   &  87 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 1   & 0   & 0   & 0  \\\\\n",
       "\t 5   &  92 & 0   & 0   & 0   & 0   & 0   & 1   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 6   &  78 & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| ID | tweet_popularity | 2019 | academic | also | analytics | annual | another | app | april | ... | washington | way | week | well | will | work | workplace | year | years | youll |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1   | 106 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "| 2   | 105 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "| 3   |  98 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "| 4   |  87 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   |\n",
       "| 5   |  92 | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "| 6   |  78 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
       "\n"
      ],
      "text/plain": [
       "  ID tweet_popularity 2019 academic also analytics annual another app april ...\n",
       "1 1  106              0    0        0    0         0      0       0   0     ...\n",
       "2 2  105              0    0        0    0         0      0       0   0     ...\n",
       "3 3   98              0    0        0    0         0      0       0   0     ...\n",
       "4 4   87              0    0        0    0         0      0       0   0     ...\n",
       "5 5   92              0    0        0    0         0      1       0   0     ...\n",
       "6 6   78              0    0        0    0         0      0       0   0     ...\n",
       "  washington way week well will work workplace year years youll\n",
       "1 0          0   0    0    0    0    0         0    0     0    \n",
       "2 0          0   0    0    0    0    0         0    0     0    \n",
       "3 0          0   0    0    0    0    0         0    0     0    \n",
       "4 0          0   0    0    0    0    1         0    0     0    \n",
       "5 0          0   0    0    0    0    0         0    0     0    \n",
       "6 0          0   0    0    0    0    0         0    0     0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create tweet popularity score\n",
    "tweet_popularity <- mutate(tweets_preprocessed, tweet_popularity = favorite_count + retweet_count) %>%\n",
    "select(tweet_popularity)\n",
    "\n",
    "#add these scores to our document term matrix (our predictors)\n",
    "model_data <- cbind(DTM_df, tweet_popularity)\n",
    "\n",
    "#also add in tweet ID number so that we have an ID\n",
    "model_data$ID <- seq.int(nrow(model_data))\n",
    "\n",
    "#move ID and tweet popularity to front of dataset (for easy accessiblity)\n",
    "model_data <- select(model_data, ID, tweet_popularity, everything())\n",
    "head(model_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the Caret R Package (https://topepo.github.io/caret/)\n",
    "* Caret actually does contain any machine learning algorithms\n",
    "* Caret provides a common framework/syntax to access many other packages that do contain machine learning algorithms\n",
    "* Caret centralizes tuning of hyperparameters across algorithms\n",
    "* Caret allows you to run multiple machine learning algorithms using the same framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first set a seed for reproducibility of our results. There are a lot of \"random\" parameters so you might try a few seed and make sure your results don't change dramatically. \n",
    "\n",
    "We'll also set up a set up a training and a test set. Here we're using an 80/20 split. Our models will be trained on 80% of the data and we will test our model on 20% of the data. This will give us an estimate of how well our models perform out-of-sample.\n",
    "\n",
    "In addition, we'll set up a k-fold cross validation training the model on the training set. The data is divided into k sub datasets (in our case, 5). Each k-fold is used as a holdout sample and model performance is then averaged across all folds. This helps with over and underfitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for reproducibility\n",
    "set.seed(167)\n",
    "\n",
    "# let's create a holdout dataset\n",
    "index <- createDataPartition(model_data$ID, p=0.80, list=FALSE)\n",
    "training_df <- model_data[index,]\n",
    "test_df <- model_data[-index,]\n",
    "\n",
    "# create Kfold index\n",
    "index <- createFolds(training_df$ID, k=5)\n",
    "\n",
    "#clean up our final datasets\n",
    "training_df<-training_df[-1] #remove id var\n",
    "test_df<-test_df[-1] # remove id var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to decide which models to use. There are a ton (see https://topepo.github.io/caret/available-models.html for a list).\n",
    "\n",
    "For this demonstration we'll use three:\n",
    "\n",
    "* Elastic Net (glmnet)\n",
    "* Stochastic Gradient Boosting (gbm)\n",
    "* Support Vector Machines with Linear Kernel (svmLinear)\n",
    "\n",
    "\n",
    "Here are a few \"gentle introduction\" resources for understanding each:\n",
    "\n",
    "Elastic Net: https://towardsdatascience.com/regression-analysis-lasso-ridge-and-elastic-net-9e65dc61d6d3\n",
    "\n",
    "Stochastic Gradient Boosting: https://towardsdatascience.com/understanding-gradient-boosting-machines-9be756fe76ab\n",
    "\n",
    "Support Vector Machines: https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's set up vectors of algorithms to look at\n",
    "algo_vec <- c(\"glmnet\", \"gbm\", \"svmLinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use Caret to run each of the algorithms on our data. This function creates a results data frame that includes each of the models we specified above as well as the out-of-sample validity (the correlation between the predicted tweet popularity scores and the actual tweet popularity scores). Once you run this, you should get a bunch of output that will show you each step of the training process for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Fold1: alpha=0.100, lambda=39.8 \n",
      "- Fold1: alpha=0.100, lambda=39.8 \n",
      "+ Fold1: alpha=0.325, lambda=39.8 \n",
      "- Fold1: alpha=0.325, lambda=39.8 \n",
      "+ Fold1: alpha=0.550, lambda=39.8 \n",
      "- Fold1: alpha=0.550, lambda=39.8 \n",
      "+ Fold1: alpha=0.775, lambda=39.8 \n",
      "- Fold1: alpha=0.775, lambda=39.8 \n",
      "+ Fold1: alpha=1.000, lambda=39.8 \n",
      "- Fold1: alpha=1.000, lambda=39.8 \n",
      "+ Fold2: alpha=0.100, lambda=39.8 \n",
      "- Fold2: alpha=0.100, lambda=39.8 \n",
      "+ Fold2: alpha=0.325, lambda=39.8 \n",
      "- Fold2: alpha=0.325, lambda=39.8 \n",
      "+ Fold2: alpha=0.550, lambda=39.8 \n",
      "- Fold2: alpha=0.550, lambda=39.8 \n",
      "+ Fold2: alpha=0.775, lambda=39.8 \n",
      "- Fold2: alpha=0.775, lambda=39.8 \n",
      "+ Fold2: alpha=1.000, lambda=39.8 \n",
      "- Fold2: alpha=1.000, lambda=39.8 \n",
      "+ Fold3: alpha=0.100, lambda=39.8 \n",
      "- Fold3: alpha=0.100, lambda=39.8 \n",
      "+ Fold3: alpha=0.325, lambda=39.8 \n",
      "- Fold3: alpha=0.325, lambda=39.8 \n",
      "+ Fold3: alpha=0.550, lambda=39.8 \n",
      "- Fold3: alpha=0.550, lambda=39.8 \n",
      "+ Fold3: alpha=0.775, lambda=39.8 \n",
      "- Fold3: alpha=0.775, lambda=39.8 \n",
      "+ Fold3: alpha=1.000, lambda=39.8 \n",
      "- Fold3: alpha=1.000, lambda=39.8 \n",
      "+ Fold4: alpha=0.100, lambda=39.8 \n",
      "- Fold4: alpha=0.100, lambda=39.8 \n",
      "+ Fold4: alpha=0.325, lambda=39.8 \n",
      "- Fold4: alpha=0.325, lambda=39.8 \n",
      "+ Fold4: alpha=0.550, lambda=39.8 \n",
      "- Fold4: alpha=0.550, lambda=39.8 \n",
      "+ Fold4: alpha=0.775, lambda=39.8 \n",
      "- Fold4: alpha=0.775, lambda=39.8 \n",
      "+ Fold4: alpha=1.000, lambda=39.8 \n",
      "- Fold4: alpha=1.000, lambda=39.8 \n",
      "+ Fold5: alpha=0.100, lambda=39.8 \n",
      "- Fold5: alpha=0.100, lambda=39.8 \n",
      "+ Fold5: alpha=0.325, lambda=39.8 \n",
      "- Fold5: alpha=0.325, lambda=39.8 \n",
      "+ Fold5: alpha=0.550, lambda=39.8 \n",
      "- Fold5: alpha=0.550, lambda=39.8 \n",
      "+ Fold5: alpha=0.775, lambda=39.8 \n",
      "- Fold5: alpha=0.775, lambda=39.8 \n",
      "+ Fold5: alpha=1.000, lambda=39.8 \n",
      "- Fold5: alpha=1.000, lambda=39.8 \n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting alpha = 1, lambda = 39.8 on full training set\n",
      "+ Fold1: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   454869.9787             nan     0.1000 -170.1735\n",
      "     2   453410.8090             nan     0.1000  973.2335\n",
      "     3   453431.1440             nan     0.1000 -183.6679\n",
      "     4   453336.7605             nan     0.1000 -579.2814\n",
      "     5   453446.3169             nan     0.1000 -2583.9610\n",
      "     6   452192.7587             nan     0.1000  824.5712\n",
      "     7   452367.5913             nan     0.1000 -1066.7439\n",
      "     8   452275.9619             nan     0.1000   29.6013\n",
      "     9   452168.2576             nan     0.1000 -134.8735\n",
      "    10   452276.4125             nan     0.1000 -566.7407\n",
      "    20   450911.7974             nan     0.1000 -451.3329\n",
      "    40   448425.9277             nan     0.1000 -1518.7641\n",
      "    60   447680.2299             nan     0.1000   -7.2030\n",
      "    80   447699.5909             nan     0.1000 -2397.3606\n",
      "   100   446581.9713             nan     0.1000 -543.8272\n",
      "   120   446484.5952             nan     0.1000  222.7527\n",
      "   140   445475.7100             nan     0.1000  -80.9266\n",
      "   160   444434.6078             nan     0.1000 -1855.5233\n",
      "   180   441708.5068             nan     0.1000  -30.4716\n",
      "   200   441900.9425             nan     0.1000 -531.2152\n",
      "   220   440574.4225             nan     0.1000 -132.6314\n",
      "   240   440343.0287             nan     0.1000  -29.7424\n",
      "   250   439524.4762             nan     0.1000 -646.3347\n",
      "\n",
      "- Fold1: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold1: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   454863.1705             nan     0.1000  -28.6807\n",
      "     2   454923.0573             nan     0.1000 -1642.0936\n",
      "     3   454896.2067             nan     0.1000  -18.8450\n",
      "     4   454865.9175             nan     0.1000 -216.1549\n",
      "     5   454873.4945             nan     0.1000 -573.8229\n",
      "     6   453166.3911             nan     0.1000  236.4166\n",
      "     7   453085.8549             nan     0.1000 -166.7769\n",
      "     8   453090.1023             nan     0.1000   -9.8541\n",
      "     9   453227.3182             nan     0.1000 -1001.8782\n",
      "    10   452018.7667             nan     0.1000  772.2794\n",
      "    20   451313.8628             nan     0.1000   44.3092\n",
      "    40   447486.6143             nan     0.1000 -437.1221\n",
      "    60   447161.4920             nan     0.1000 -1479.3262\n",
      "    80   447016.1621             nan     0.1000 -1707.6753\n",
      "   100   446639.2375             nan     0.1000 -234.5069\n",
      "   120   446475.2792             nan     0.1000 -1462.6797\n",
      "   140   446038.5358             nan     0.1000  -70.9480\n",
      "   160   445709.4378             nan     0.1000 -320.1083\n",
      "   180   444683.6763             nan     0.1000  -28.8251\n",
      "   200   444354.7261             nan     0.1000 -1396.7778\n",
      "   220   443605.8112             nan     0.1000 -460.7627\n",
      "   240   443365.4642             nan     0.1000 -706.3184\n",
      "   250   443176.2124             nan     0.1000   75.3819\n",
      "\n",
      "- Fold1: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold1: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   454871.1028             nan     0.1000 -193.5362\n",
      "     2   454893.9463             nan     0.1000 -174.3450\n",
      "     3   454795.2389             nan     0.1000 -1991.6844\n",
      "     4   454806.2517             nan     0.1000 -179.3838\n",
      "     5   454804.1121             nan     0.1000  -15.1067\n",
      "     6   453218.4051             nan     0.1000  819.1475\n",
      "     7   453228.3794             nan     0.1000 -975.2563\n",
      "     8   451971.2614             nan     0.1000  679.8374\n",
      "     9   450961.3795             nan     0.1000  495.1112\n",
      "    10   450975.3201             nan     0.1000 -179.5115\n",
      "    20   449375.8408             nan     0.1000  -10.7293\n",
      "    40   448533.9902             nan     0.1000   98.4050\n",
      "    60   445177.6926             nan     0.1000 -262.0031\n",
      "    80   444919.8567             nan     0.1000  -24.9716\n",
      "   100   444654.0256             nan     0.1000 -3098.3897\n",
      "   120   444133.0686             nan     0.1000 -109.2102\n",
      "   140   444459.1577             nan     0.1000 -219.0510\n",
      "   160   443847.6153             nan     0.1000 -945.0587\n",
      "   180   443536.0968             nan     0.1000 -277.0939\n",
      "   200   442015.3827             nan     0.1000 -668.8236\n",
      "   220   440503.1758             nan     0.1000 -228.2254\n",
      "   240   439684.3475             nan     0.1000 -157.7038\n",
      "   250   439478.1577             nan     0.1000 -532.9166\n",
      "\n",
      "- Fold1: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold1: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   454870.0354             nan     0.1000 -171.3519\n",
      "     2   453654.6743             nan     0.1000  743.3326\n",
      "     3   453609.4106             nan     0.1000 -564.6961\n",
      "     4   453667.7198             nan     0.1000 -985.9649\n",
      "     5   452305.6060             nan     0.1000  714.1172\n",
      "     6   452293.1061             nan     0.1000  -22.4116\n",
      "     7   452314.7655             nan     0.1000 -157.8183\n",
      "     8   452297.9021             nan     0.1000  -26.2656\n",
      "     9   452283.2395             nan     0.1000 -218.8856\n",
      "    10   452292.6222             nan     0.1000 -173.2771\n",
      "    20   450445.8125             nan     0.1000  281.6303\n",
      "    40   447917.7824             nan     0.1000   51.0758\n",
      "    60   447127.6314             nan     0.1000 -284.0965\n",
      "    80   444949.7794             nan     0.1000 -1047.5569\n",
      "   100   444698.8125             nan     0.1000 -156.3501\n",
      "   120   444374.8759             nan     0.1000    8.5459\n",
      "   140   444389.4990             nan     0.1000 -190.0453\n",
      "   160   443746.9179             nan     0.1000 -548.1924\n",
      "   180   442277.5168             nan     0.1000  -65.5536\n",
      "   200   442178.1844             nan     0.1000 -628.4126\n",
      "   220   440988.1802             nan     0.1000 -1958.2678\n",
      "   240   439904.3713             nan     0.1000 -1846.6530\n",
      "   250   440087.2135             nan     0.1000 -123.0928\n",
      "\n",
      "- Fold1: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold1: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   453388.9625             nan     0.1000 1105.0863\n",
      "     2   452371.6026             nan     0.1000  420.5385\n",
      "     3   451053.7766             nan     0.1000 -1043.0396\n",
      "     4   451068.9294             nan     0.1000 -2573.4015\n",
      "     5   451027.4176             nan     0.1000 -572.0113\n",
      "     6   450588.4059             nan     0.1000 -662.9464\n",
      "     7   449984.0860             nan     0.1000  442.1053\n",
      "     8   450083.3555             nan     0.1000 -988.7580\n",
      "     9   449578.4519             nan     0.1000  376.4129\n",
      "    10   448908.7028             nan     0.1000 -248.6652\n",
      "    20   448302.5969             nan     0.1000 -1062.5936\n",
      "    40   447035.8208             nan     0.1000 -608.0141\n",
      "    60   444780.9461             nan     0.1000  -20.7987\n",
      "    80   444517.9718             nan     0.1000   37.2307\n",
      "   100   444375.9444             nan     0.1000 -236.4344\n",
      "   120   444039.5898             nan     0.1000 -113.6961\n",
      "   140   444001.3378             nan     0.1000 -259.8347\n",
      "   160   442412.8595             nan     0.1000 -975.0896\n",
      "   180   442448.0184             nan     0.1000 -1132.5977\n",
      "   200   442374.7882             nan     0.1000 -1010.1744\n",
      "   220   442370.5710             nan     0.1000  -42.0202\n",
      "   240   442279.7702             nan     0.1000 -880.7070\n",
      "   250   442340.3285             nan     0.1000  -37.1116\n",
      "\n",
      "- Fold1: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold2: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   404269.6579             nan     0.1000  275.4584\n",
      "     2   402456.5080             nan     0.1000  958.5195\n",
      "     3   402618.4940             nan     0.1000 -1750.7659\n",
      "     4   400807.2991             nan     0.1000   77.9468\n",
      "     5   400804.4946             nan     0.1000    5.2683\n",
      "     6   400027.5831             nan     0.1000  118.5298\n",
      "     7   399971.5571             nan     0.1000 -203.8879\n",
      "     8   399810.9990             nan     0.1000 -338.9354\n",
      "     9   399812.7885             nan     0.1000  -19.8218\n",
      "    10   399096.5621             nan     0.1000  262.2535\n",
      "    20   397599.4252             nan     0.1000 -148.0643\n",
      "    40   395107.6207             nan     0.1000   39.7717\n",
      "    60   391773.4405             nan     0.1000 -726.6715\n",
      "    80   391327.3443             nan     0.1000  -87.9855\n",
      "   100   390809.7276             nan     0.1000 -146.0975\n",
      "   120   390573.7589             nan     0.1000 -1167.6181\n",
      "   140   389679.4313             nan     0.1000 -3603.5620\n",
      "   160   389146.3498             nan     0.1000 -1662.9433\n",
      "   180   389078.9593             nan     0.1000 -251.8843\n",
      "   200   388732.5462             nan     0.1000   16.3599\n",
      "   220   388686.3101             nan     0.1000 -2100.3408\n",
      "   240   388746.4666             nan     0.1000 -330.9119\n",
      "   250   387575.4260             nan     0.1000 -527.2841\n",
      "\n",
      "- Fold2: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold2: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   404646.4323             nan     0.1000 -1048.8021\n",
      "     2   404310.5030             nan     0.1000 -380.2361\n",
      "     3   402418.6515             nan     0.1000 -2046.4284\n",
      "     4   402124.8135             nan     0.1000 -506.4289\n",
      "     5   402621.1433             nan     0.1000 -3554.3564\n",
      "     6   402459.5902             nan     0.1000   72.4648\n",
      "     7   402215.9412             nan     0.1000  126.0265\n",
      "     8   402243.0486             nan     0.1000  -59.3709\n",
      "     9   401892.2372             nan     0.1000 -468.0689\n",
      "    10   400642.2993             nan     0.1000 -514.2696\n",
      "    20   396741.7099             nan     0.1000 -507.2185\n",
      "    40   393626.3768             nan     0.1000  -55.6587\n",
      "    60   391162.7097             nan     0.1000 -427.3625\n",
      "    80   390276.3383             nan     0.1000  196.9918\n",
      "   100   390396.9737             nan     0.1000 -1207.7846\n",
      "   120   389356.9218             nan     0.1000 -461.2211\n",
      "   140   388993.4277             nan     0.1000 -778.1742\n",
      "   160   388847.4735             nan     0.1000 -460.2198\n",
      "   180   388985.9778             nan     0.1000 -1947.5479\n",
      "   200   387564.8163             nan     0.1000  -61.2900\n",
      "   220   387676.8454             nan     0.1000  -23.8085\n",
      "   240   387694.8107             nan     0.1000 -1120.7149\n",
      "   250   385676.8644             nan     0.1000 -244.2052\n",
      "\n",
      "- Fold2: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold2: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   404597.6022             nan     0.1000  -23.3711\n",
      "     2   404600.9317             nan     0.1000 -196.7021\n",
      "     3   404604.6790             nan     0.1000  -18.2983\n",
      "     4   403213.2690             nan     0.1000 1298.9769\n",
      "     5   403246.2287             nan     0.1000 -1762.3579\n",
      "     6   403278.7126             nan     0.1000 -153.0146\n",
      "     7   402970.7977             nan     0.1000   22.5826\n",
      "     8   403219.1620             nan     0.1000 -1696.3695\n",
      "     9   403771.7707             nan     0.1000 -3406.8202\n",
      "    10   403427.6901             nan     0.1000  -56.7088\n",
      "    20   398186.0157             nan     0.1000 -1900.9747\n",
      "    40   393270.3495             nan     0.1000   18.9985\n",
      "    60   392813.0696             nan     0.1000 -1062.7563\n",
      "    80   391349.2607             nan     0.1000  186.3684\n",
      "   100   390687.6397             nan     0.1000 -1565.0876\n",
      "   120   389931.7616             nan     0.1000 -945.7884\n",
      "   140   389641.7392             nan     0.1000 -514.3676\n",
      "   160   389261.9902             nan     0.1000   -1.5161\n",
      "   180   388501.4026             nan     0.1000    5.6028\n",
      "   200   389040.9322             nan     0.1000 -1243.5673\n",
      "   220   387712.9967             nan     0.1000  -41.0386\n",
      "   240   386877.1336             nan     0.1000  -81.6165\n",
      "   250   386055.4648             nan     0.1000   59.9282\n",
      "\n",
      "- Fold2: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold2: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   404605.3710             nan     0.1000 -186.5159\n",
      "     2   403210.4699             nan     0.1000  908.9066\n",
      "     3   401438.5913             nan     0.1000 -937.5250\n",
      "     4   401428.2289             nan     0.1000   17.7276\n",
      "     5   401341.2964             nan     0.1000 -131.5047\n",
      "     6   401272.8140             nan     0.1000 -488.1132\n",
      "     7   401267.2223             nan     0.1000 -484.8356\n",
      "     8   401264.6142             nan     0.1000 -189.3476\n",
      "     9   401266.9387             nan     0.1000 -190.5670\n",
      "    10   400919.0433             nan     0.1000  387.2228\n",
      "    20   397912.6160             nan     0.1000  -74.9545\n",
      "    40   396693.6495             nan     0.1000  135.8994\n",
      "    60   395285.9027             nan     0.1000 -315.5427\n",
      "    80   394833.0421             nan     0.1000  -70.4685\n",
      "   100   394188.4346             nan     0.1000  -11.9333\n",
      "   120   393406.8594             nan     0.1000 -924.8941\n",
      "   140   393294.6232             nan     0.1000  -70.3878\n",
      "   160   393343.0734             nan     0.1000 -577.5543\n",
      "   180   391489.9941             nan     0.1000 -1199.6204\n",
      "   200   391970.1549             nan     0.1000 -464.7348\n",
      "   220   390912.2512             nan     0.1000 -233.2012\n",
      "   240   388153.9842             nan     0.1000 -198.7522\n",
      "   250   388114.2585             nan     0.1000 -225.6903\n",
      "\n",
      "- Fold2: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold2: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   402982.0679             nan     0.1000 1005.6078\n",
      "     2   403123.5547             nan     0.1000 -1689.5977\n",
      "     3   403302.5635             nan     0.1000 -997.7185\n",
      "     4   402084.6921             nan     0.1000 1023.4460\n",
      "     5   401965.6284             nan     0.1000 -505.1376\n",
      "     6   401989.3240             nan     0.1000  -51.8378\n",
      "     7   401428.3221             nan     0.1000  183.6234\n",
      "     8   401265.2474             nan     0.1000 -127.3504\n",
      "     9   401309.8116             nan     0.1000 -131.1102\n",
      "    10   401124.1655             nan     0.1000  240.2343\n",
      "    20   399662.6177             nan     0.1000   59.3020\n",
      "    40   395513.3665             nan     0.1000 -740.1314\n",
      "    60   394241.9567             nan     0.1000 -1126.2312\n",
      "    80   393355.5305             nan     0.1000  -82.2085\n",
      "   100   392121.0623             nan     0.1000 -212.3771\n",
      "   120   392051.3396             nan     0.1000 -196.6593\n",
      "   140   390726.2337             nan     0.1000 -981.7650\n",
      "   160   389605.2412             nan     0.1000 -195.7662\n",
      "   180   389538.2466             nan     0.1000 -785.5251\n",
      "   200   388810.2942             nan     0.1000  -26.2213\n",
      "   220   388791.4739             nan     0.1000 -448.8624\n",
      "   240   388827.4172             nan     0.1000 -522.4559\n",
      "   250   388817.9484             nan     0.1000  -21.1276\n",
      "\n",
      "- Fold2: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold3: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   361826.6348             nan     0.1000  554.0839\n",
      "     2   361819.6014             nan     0.1000  -85.2624\n",
      "     3   360850.7051             nan     0.1000 -1852.3492\n",
      "     4   360312.0809             nan     0.1000  310.7167\n",
      "     5   359832.2222             nan     0.1000  173.5490\n",
      "     6   359760.0319             nan     0.1000 -297.9367\n",
      "     7   359683.9006             nan     0.1000  105.6225\n",
      "     8   359325.8281             nan     0.1000 -292.9902\n",
      "     9   359324.2187             nan     0.1000   -0.7999\n",
      "    10   359311.1894             nan     0.1000 -668.9418\n",
      "    20   358894.3131             nan     0.1000 -353.7317\n",
      "    40   356167.1725             nan     0.1000 -2071.9031\n",
      "    60   355926.0229             nan     0.1000 -488.9249\n",
      "    80   352784.7297             nan     0.1000 -105.7638\n",
      "   100   352791.2328             nan     0.1000 -548.0274\n",
      "   120   352686.6064             nan     0.1000 -168.5777\n",
      "   140   352557.9479             nan     0.1000  -10.7733\n",
      "   160   352933.3136             nan     0.1000 -256.7601\n",
      "   180   352508.4332             nan     0.1000 -447.8492\n",
      "   200   351517.6181             nan     0.1000 -704.4761\n",
      "   220   351558.3064             nan     0.1000  -76.2725\n",
      "   240   351156.1959             nan     0.1000   18.4092\n",
      "   250   350984.4626             nan     0.1000    2.9427\n",
      "\n",
      "- Fold3: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold3: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   362862.7165             nan     0.1000  -84.6011\n",
      "     2   362861.7421             nan     0.1000    0.6693\n",
      "     3   362864.5602             nan     0.1000 -336.1706\n",
      "     4   362757.3108             nan     0.1000   70.6744\n",
      "     5   361951.9583             nan     0.1000  423.0476\n",
      "     6   361951.9017             nan     0.1000   -0.1429\n",
      "     7   361990.3189             nan     0.1000 -764.3547\n",
      "     8   362084.4823             nan     0.1000 -2439.9726\n",
      "     9   361871.2052             nan     0.1000 -203.5880\n",
      "    10   361047.4768             nan     0.1000  525.1501\n",
      "    20   361305.8528             nan     0.1000  -96.5473\n",
      "    40   358228.6206             nan     0.1000  -50.5587\n",
      "    60   357589.1371             nan     0.1000  -83.7317\n",
      "    80   357055.5028             nan     0.1000  -52.6590\n",
      "   100   356640.7506             nan     0.1000 -1428.1334\n",
      "   120   355323.3472             nan     0.1000 -185.3237\n",
      "   140   355830.7409             nan     0.1000 -174.6108\n",
      "   160   355249.1783             nan     0.1000 -208.4414\n",
      "   180   354836.1443             nan     0.1000   -9.5213\n",
      "   200   354329.7560             nan     0.1000 -118.0312\n",
      "   220   354534.7507             nan     0.1000 -966.9417\n",
      "   240   353170.4403             nan     0.1000 -319.9755\n",
      "   250   352805.2123             nan     0.1000 -220.7296\n",
      "\n",
      "- Fold3: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold3: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   362862.9310             nan     0.1000  -89.1061\n",
      "     2   362317.0922             nan     0.1000 -657.1018\n",
      "     3   362296.1499             nan     0.1000    9.7446\n",
      "     4   362164.2823             nan     0.1000  170.1101\n",
      "     5   362147.4498             nan     0.1000   16.1731\n",
      "     6   362321.2237             nan     0.1000 -1354.9321\n",
      "     7   361862.3894             nan     0.1000    8.5529\n",
      "     8   361719.7549             nan     0.1000  -25.2770\n",
      "     9   360601.2882             nan     0.1000 -484.6098\n",
      "    10   360592.4185             nan     0.1000    9.7232\n",
      "    20   358956.0178             nan     0.1000   79.7827\n",
      "    40   355404.3587             nan     0.1000 -124.9279\n",
      "    60   353135.7596             nan     0.1000 -164.9396\n",
      "    80   352988.8385             nan     0.1000  -98.8056\n",
      "   100   352996.7569             nan     0.1000 -354.9588\n",
      "   120   353030.9697             nan     0.1000 -341.3072\n",
      "   140   353093.6229             nan     0.1000 -371.8953\n",
      "   160   353107.1520             nan     0.1000 -619.9911\n",
      "   180   352961.8316             nan     0.1000  -52.6992\n",
      "   200   353394.3062             nan     0.1000 -1534.9218\n",
      "   220   353017.5712             nan     0.1000 -2106.4544\n",
      "   240   352478.0464             nan     0.1000 -753.3520\n",
      "   250   352311.0565             nan     0.1000 -411.8905\n",
      "\n",
      "- Fold3: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold3: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   362437.9223             nan     0.1000 -319.7527\n",
      "     2   362359.2324             nan     0.1000   -5.4046\n",
      "     3   362511.2889             nan     0.1000 -2101.8415\n",
      "     4   362592.2391             nan     0.1000 -318.1632\n",
      "     5   362411.5579             nan     0.1000 -775.2604\n",
      "     6   362359.7419             nan     0.1000   73.2356\n",
      "     7   362349.7866             nan     0.1000    9.6362\n",
      "     8   362322.5238             nan     0.1000  -83.7883\n",
      "     9   362304.6630             nan     0.1000 -770.1546\n",
      "    10   362372.2184             nan     0.1000 -326.0366\n",
      "    20   362088.3721             nan     0.1000   79.9741\n",
      "    40   357405.3268             nan     0.1000  -41.6439\n",
      "    60   356310.2749             nan     0.1000   70.2494\n",
      "    80   355798.4228             nan     0.1000 -884.6427\n",
      "   100   355738.5656             nan     0.1000  -26.6477\n",
      "   120   355621.8845             nan     0.1000 -273.9554\n",
      "   140   354169.5389             nan     0.1000  392.4682\n",
      "   160   354152.5458             nan     0.1000 -838.6226\n",
      "   180   352573.6696             nan     0.1000   -8.9564\n",
      "   200   352083.0619             nan     0.1000 -214.6760\n",
      "   220   352185.4609             nan     0.1000 -4039.2536\n",
      "   240   352287.4854             nan     0.1000  -12.5050\n",
      "   250   351377.1432             nan     0.1000  -15.9708\n",
      "\n",
      "- Fold3: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold3: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   362896.6998             nan     0.1000 -798.2513\n",
      "     2   362662.8235             nan     0.1000 -596.0223\n",
      "     3   362715.8421             nan     0.1000 -1337.1112\n",
      "     4   362736.1927             nan     0.1000  -71.7683\n",
      "     5   362801.4829             nan     0.1000 -325.3002\n",
      "     6   361437.3782             nan     0.1000 -851.9080\n",
      "     7   360485.4394             nan     0.1000 -1217.6585\n",
      "     8   360457.3869             nan     0.1000  -98.2553\n",
      "     9   360446.2838             nan     0.1000  -90.7871\n",
      "    10   360456.0627             nan     0.1000 -380.4359\n",
      "    20   360716.0062             nan     0.1000 -733.5003\n",
      "    40   358563.2894             nan     0.1000  -54.1349\n",
      "    60   354745.6929             nan     0.1000 -461.9223\n",
      "    80   353138.2815             nan     0.1000 -328.9179\n",
      "   100   352278.6383             nan     0.1000 -317.6585\n",
      "   120   352042.2375             nan     0.1000  -33.0837\n",
      "   140   349992.2599             nan     0.1000 -238.0653\n",
      "   160   348588.8912             nan     0.1000 -169.7212\n",
      "   180   347350.0661             nan     0.1000    0.3316\n",
      "   200   347135.9935             nan     0.1000 -252.9946\n",
      "   220   347386.9485             nan     0.1000 -1045.8298\n",
      "   240   347086.8469             nan     0.1000 -162.1559\n",
      "   250   347099.7573             nan     0.1000 -1649.3868\n",
      "\n",
      "- Fold3: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold4: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   479844.6105             nan     0.1000 -550.4236\n",
      "     2   478962.0050             nan     0.1000   42.1697\n",
      "     3   478963.5135             nan     0.1000   -3.0945\n",
      "     4   479136.4930             nan     0.1000 -1078.5900\n",
      "     5   478956.1400             nan     0.1000 -460.3092\n",
      "     6   478360.8859             nan     0.1000   28.7846\n",
      "     7   477922.6344             nan     0.1000  317.0042\n",
      "     8   477740.6339             nan     0.1000  -53.2370\n",
      "     9   477717.9278             nan     0.1000   36.7926\n",
      "    10   477645.0100             nan     0.1000 -550.4646\n",
      "    20   474938.3940             nan     0.1000 -524.9531\n",
      "    40   473420.8018             nan     0.1000 -1809.6407\n",
      "    60   472134.9091             nan     0.1000 -1629.4596\n",
      "    80   471434.9438             nan     0.1000 -643.6741\n",
      "   100   470596.0760             nan     0.1000 -1744.3692\n",
      "   120   470235.0709             nan     0.1000   57.4973\n",
      "   140   469492.1727             nan     0.1000 -472.3857\n",
      "   160   467889.2427             nan     0.1000 -515.7692\n",
      "   180   467915.4001             nan     0.1000 -210.9242\n",
      "   200   467810.5718             nan     0.1000 -268.6858\n",
      "   220   468172.6723             nan     0.1000 -389.2503\n",
      "   240   468091.0743             nan     0.1000 -1512.2686\n",
      "   250   467929.7410             nan     0.1000  -38.2176\n",
      "\n",
      "- Fold4: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold4: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   477793.3749             nan     0.1000  -40.2435\n",
      "     2   477774.4700             nan     0.1000 -989.5317\n",
      "     3   477882.1738             nan     0.1000 -1892.1043\n",
      "     4   477966.4806             nan     0.1000 -549.1740\n",
      "     5   477406.3015             nan     0.1000 -987.3185\n",
      "     6   476560.4039             nan     0.1000 -575.2470\n",
      "     7   476471.4842             nan     0.1000 -485.0984\n",
      "     8   476452.1067             nan     0.1000 -189.2224\n",
      "     9   476466.9391             nan     0.1000 -505.4302\n",
      "    10   476470.6782             nan     0.1000  -11.1404\n",
      "    20   474611.5123             nan     0.1000 -1042.0127\n",
      "    40   471717.1309             nan     0.1000 -1401.7344\n",
      "    60   470744.1059             nan     0.1000 -324.5068\n",
      "    80   469580.4319             nan     0.1000 -504.5300\n",
      "   100   469644.8283             nan     0.1000 -219.7470\n",
      "   120   469440.3157             nan     0.1000    9.2459\n",
      "   140   469039.0492             nan     0.1000 -214.0264\n",
      "   160   468969.5693             nan     0.1000 -584.2350\n",
      "   180   468655.0704             nan     0.1000 -2181.2139\n",
      "   200   468441.8016             nan     0.1000 -144.4802\n",
      "   220   467885.8483             nan     0.1000 -1105.2866\n",
      "   240   467050.1084             nan     0.1000 -103.6006\n",
      "   250   467042.1746             nan     0.1000 -217.0653\n",
      "\n",
      "- Fold4: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold4: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   479818.6986             nan     0.1000  -11.9081\n",
      "     2   479818.4613             nan     0.1000  -33.0885\n",
      "     3   479436.6823             nan     0.1000 -419.9555\n",
      "     4   479611.0877             nan     0.1000 -1672.4904\n",
      "     5   478969.4937             nan     0.1000  736.7086\n",
      "     6   478221.7846             nan     0.1000  519.1245\n",
      "     7   477824.0963             nan     0.1000 -1076.9712\n",
      "     8   476948.1761             nan     0.1000  199.0032\n",
      "     9   477454.8792             nan     0.1000 -1519.9999\n",
      "    10   476891.7838             nan     0.1000 -223.7556\n",
      "    20   476560.8958             nan     0.1000   33.2581\n",
      "    40   474453.0759             nan     0.1000   -3.9284\n",
      "    60   473728.5902             nan     0.1000 -584.0411\n",
      "    80   471668.6246             nan     0.1000 -1053.9481\n",
      "   100   470167.1759             nan     0.1000 -255.1967\n",
      "   120   469683.1580             nan     0.1000  -10.4430\n",
      "   140   469581.5337             nan     0.1000   13.4309\n",
      "   160   469646.5144             nan     0.1000 -474.0523\n",
      "   180   468865.6536             nan     0.1000  -83.5093\n",
      "   200   468715.2578             nan     0.1000 -131.5319\n",
      "   220   468199.3995             nan     0.1000 -431.9538\n",
      "   240   467564.2301             nan     0.1000 -1132.8703\n",
      "   250   467030.7870             nan     0.1000 -792.8152\n",
      "\n",
      "- Fold4: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold4: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   479828.2616             nan     0.1000 -210.6517\n",
      "     2   479126.8455             nan     0.1000  633.7829\n",
      "     3   478719.2162             nan     0.1000  405.0794\n",
      "     4   478698.3879             nan     0.1000  -10.0317\n",
      "     5   478013.5857             nan     0.1000  483.4698\n",
      "     6   477725.2250             nan     0.1000  -96.8895\n",
      "     7   477729.5016             nan     0.1000  -25.8844\n",
      "     8   477435.5503             nan     0.1000 -590.6618\n",
      "     9   477361.0003             nan     0.1000 -1007.9935\n",
      "    10   476892.6284             nan     0.1000  253.5977\n",
      "    20   473765.9145             nan     0.1000 -524.7658\n",
      "    40   472071.1374             nan     0.1000  -14.8852\n",
      "    60   472229.3003             nan     0.1000  -59.0831\n",
      "    80   471066.9083             nan     0.1000 -749.5932\n",
      "   100   470727.2781             nan     0.1000 -1512.6906\n",
      "   120   470683.5999             nan     0.1000   -2.5436\n",
      "   140   470164.7892             nan     0.1000 -230.5220\n",
      "   160   468975.6005             nan     0.1000  -10.3597\n",
      "   180   469439.9279             nan     0.1000 -1504.0967\n",
      "   200   468668.4540             nan     0.1000 -1600.6724\n",
      "   220   468606.6735             nan     0.1000  -39.1087\n",
      "   240   468380.1665             nan     0.1000 -1752.8655\n",
      "   250   468286.0931             nan     0.1000 -319.0725\n",
      "\n",
      "- Fold4: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold4: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   479403.4653             nan     0.1000 -1048.2133\n",
      "     2   477849.9493             nan     0.1000 -326.6715\n",
      "     3   477103.1672             nan     0.1000 -445.2332\n",
      "     4   477345.8505             nan     0.1000 -1784.8776\n",
      "     5   476841.4743             nan     0.1000  429.1008\n",
      "     6   476795.8851             nan     0.1000   -6.8070\n",
      "     7   476438.3203             nan     0.1000  158.6953\n",
      "     8   476548.7892             nan     0.1000 -2084.7513\n",
      "     9   476223.6930             nan     0.1000  320.3276\n",
      "    10   476274.3320             nan     0.1000 -732.5860\n",
      "    20   473258.7125             nan     0.1000 -206.0085\n",
      "    40   472680.5490             nan     0.1000 -152.9335\n",
      "    60   472202.2722             nan     0.1000   -7.0602\n",
      "    80   470284.5347             nan     0.1000 -2184.6704\n",
      "   100   467301.4864             nan     0.1000 -722.9550\n",
      "   120   467068.1110             nan     0.1000  -52.8856\n",
      "   140   465661.9478             nan     0.1000 -437.1726\n",
      "   160   465803.3685             nan     0.1000   30.9147\n",
      "   180   465318.0031             nan     0.1000 -174.0342\n",
      "   200   464378.3434             nan     0.1000 -363.7446\n",
      "   220   463265.6498             nan     0.1000  -80.5299\n",
      "   240   462778.5139             nan     0.1000 -103.2144\n",
      "   250   462803.7649             nan     0.1000 -957.9532\n",
      "\n",
      "- Fold4: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold5: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   347590.2567             nan     0.1000 -966.4549\n",
      "     2   347627.9810             nan     0.1000 -180.8798\n",
      "     3   347407.9355             nan     0.1000 -959.5243\n",
      "     4   347149.5289             nan     0.1000 -573.3350\n",
      "     5   347387.4094             nan     0.1000 -3149.4891\n",
      "     6   347317.9214             nan     0.1000   50.2650\n",
      "     7   347480.9273             nan     0.1000 -703.0476\n",
      "     8   347522.6587             nan     0.1000 -129.7844\n",
      "     9   347272.0193             nan     0.1000 -261.4828\n",
      "    10   346941.2500             nan     0.1000 -1048.5594\n",
      "    20   346714.1741             nan     0.1000 -477.7386\n",
      "    40   346202.0527             nan     0.1000 -167.1957\n",
      "    60   345074.8311             nan     0.1000 -132.3538\n",
      "    80   344923.8911             nan     0.1000   -4.9397\n",
      "   100   344620.1722             nan     0.1000 -650.4902\n",
      "   120   344593.1941             nan     0.1000 -150.8790\n",
      "   140   344333.7486             nan     0.1000  -19.5714\n",
      "   160   343816.7061             nan     0.1000 -536.9974\n",
      "   180   343333.4198             nan     0.1000  -47.8186\n",
      "   200   343164.4429             nan     0.1000 -269.0649\n",
      "   220   343221.0618             nan     0.1000 -813.0358\n",
      "   240   342087.3679             nan     0.1000  110.5727\n",
      "   250   342012.1602             nan     0.1000 -481.4069\n",
      "\n",
      "- Fold5: shrinkage=0.1, interaction.depth=1, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold5: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   347892.3675             nan     0.1000 -1019.4913\n",
      "     2   347931.2359             nan     0.1000 -116.2223\n",
      "     3   347888.6439             nan     0.1000 -221.9867\n",
      "     4   347881.7791             nan     0.1000  -18.5180\n",
      "     5   347800.9074             nan     0.1000 -378.4958\n",
      "     6   347806.7031             nan     0.1000  -18.5392\n",
      "     7   347781.7771             nan     0.1000 -190.3882\n",
      "     8   347913.9606             nan     0.1000 -3545.4683\n",
      "     9   348083.0068             nan     0.1000 -982.6229\n",
      "    10   348057.1159             nan     0.1000   40.8216\n",
      "    20   345712.3852             nan     0.1000 -170.6862\n",
      "    40   345620.2276             nan     0.1000   21.8296\n",
      "    60   345066.5179             nan     0.1000 -401.8179\n",
      "    80   342455.1113             nan     0.1000 -262.1519\n",
      "   100   340562.3787             nan     0.1000 -314.5532\n",
      "   120   340230.5199             nan     0.1000  -85.1530\n",
      "   140   338691.1588             nan     0.1000 -377.6865\n",
      "   160   338152.5840             nan     0.1000  -22.8445\n",
      "   180   338374.4876             nan     0.1000 -686.8428\n",
      "   200   337239.4884             nan     0.1000  -17.9366\n",
      "   220   337107.4645             nan     0.1000 -140.1852\n",
      "   240   336936.2888             nan     0.1000 -170.0679\n",
      "   250   336678.4903             nan     0.1000 -387.6514\n",
      "\n",
      "- Fold5: shrinkage=0.1, interaction.depth=2, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold5: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   347719.1496             nan     0.1000   73.5438\n",
      "     2   347716.7430             nan     0.1000  -19.7493\n",
      "     3   347718.7959             nan     0.1000  -24.0436\n",
      "     4   347722.3125             nan     0.1000  -22.2888\n",
      "     5   347725.4188             nan     0.1000 -559.4669\n",
      "     6   347327.8122             nan     0.1000 -192.7012\n",
      "     7   346993.9301             nan     0.1000 -785.3046\n",
      "     8   346999.0857             nan     0.1000 -159.6014\n",
      "     9   346994.4478             nan     0.1000  -30.9569\n",
      "    10   346993.8631             nan     0.1000  -29.5979\n",
      "    20   346047.9856             nan     0.1000 -579.5614\n",
      "    40   345114.1163             nan     0.1000 -621.6218\n",
      "    60   344266.9797             nan     0.1000   -8.6186\n",
      "    80   342871.5359             nan     0.1000 -483.0929\n",
      "   100   342306.4329             nan     0.1000 -445.1126\n",
      "   120   342469.0729             nan     0.1000   18.9871\n",
      "   140   341986.2991             nan     0.1000  -24.3560\n",
      "   160   341332.8192             nan     0.1000 -241.0745\n",
      "   180   340650.4858             nan     0.1000 -781.5293\n",
      "   200   339867.1954             nan     0.1000 -570.2794\n",
      "   220   339051.9192             nan     0.1000   11.5273\n",
      "   240   338503.5225             nan     0.1000 -524.3902\n",
      "   250   338488.8721             nan     0.1000  -63.1710\n",
      "\n",
      "- Fold5: shrinkage=0.1, interaction.depth=3, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold5: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   347635.6831             nan     0.1000 -380.3384\n",
      "     2   347607.4456             nan     0.1000 -540.0939\n",
      "     3   346727.6439             nan     0.1000   38.9567\n",
      "     4   346855.0444             nan     0.1000 -2323.4430\n",
      "     5   346883.6118             nan     0.1000 -157.6086\n",
      "     6   346719.1875             nan     0.1000 -628.6755\n",
      "     7   346238.7591             nan     0.1000   37.4666\n",
      "     8   346072.7900             nan     0.1000 -1043.3545\n",
      "     9   346217.0559             nan     0.1000 -646.7660\n",
      "    10   346064.7935             nan     0.1000 -1789.9014\n",
      "    20   345683.1497             nan     0.1000  -18.9394\n",
      "    40   344757.2736             nan     0.1000 -529.5042\n",
      "    60   343785.5932             nan     0.1000 -252.2986\n",
      "    80   343756.6374             nan     0.1000 -1522.2771\n",
      "   100   343399.5878             nan     0.1000 -222.0175\n",
      "   120   342991.5448             nan     0.1000 -153.1604\n",
      "   140   341889.2476             nan     0.1000 -153.0624\n",
      "   160   341729.6033             nan     0.1000 -2684.6506\n",
      "   180   341102.5523             nan     0.1000 -281.2398\n",
      "   200   340951.9874             nan     0.1000 -139.8584\n",
      "   220   341051.7910             nan     0.1000   31.3756\n",
      "   240   340479.1347             nan     0.1000 -1587.4441\n",
      "   250   340599.5715             nan     0.1000 -635.4960\n",
      "\n",
      "- Fold5: shrinkage=0.1, interaction.depth=4, n.minobsinnode=10, n.trees=250 \n",
      "+ Fold5: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   347844.6472             nan     0.1000  -17.3649\n",
      "     2   347968.8048             nan     0.1000 -1187.3249\n",
      "     3   347832.4991             nan     0.1000  -81.2695\n",
      "     4   347816.6659             nan     0.1000 -209.5765\n",
      "     5   347779.4493             nan     0.1000   41.7550\n",
      "     6   347417.8582             nan     0.1000 -246.7661\n",
      "     7   347401.3661             nan     0.1000 -194.1660\n",
      "     8   347242.6253             nan     0.1000 -1011.0990\n",
      "     9   347005.5921             nan     0.1000 -244.1408\n",
      "    10   346947.3330             nan     0.1000 -1137.1835\n",
      "    20   346473.0586             nan     0.1000   -0.9504\n",
      "    40   345190.6705             nan     0.1000 -729.1800\n",
      "    60   345153.5391             nan     0.1000 -141.9349\n",
      "    80   343981.6038             nan     0.1000   -5.4946\n",
      "   100   343873.0338             nan     0.1000 -556.7477\n",
      "   120   343261.7759             nan     0.1000 -474.7685\n",
      "   140   341995.2810             nan     0.1000 -348.2770\n",
      "   160   341862.8130             nan     0.1000   19.3869\n",
      "   180   341693.9551             nan     0.1000 -1696.8997\n",
      "   200   341824.1340             nan     0.1000 -216.1304\n",
      "   220   341710.7536             nan     0.1000 -290.2821\n",
      "   240   341235.7472             nan     0.1000  100.3639\n",
      "   250   340632.5223             nan     0.1000  -26.6983\n",
      "\n",
      "- Fold5: shrinkage=0.1, interaction.depth=5, n.minobsinnode=10, n.trees=250 \n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting n.trees = 50, interaction.depth = 5, shrinkage = 0.1, n.minobsinnode = 10 on full training set\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1   408059.3684             nan     0.1000 1045.8978\n",
      "     2   405168.7129             nan     0.1000 1548.5162\n",
      "     3   402665.6172             nan     0.1000  548.8225\n",
      "     4   400452.7238             nan     0.1000  216.1403\n",
      "     5   398495.5945             nan     0.1000  408.1113\n",
      "     6   396765.7458             nan     0.1000  124.3028\n",
      "     7   394554.2988             nan     0.1000  -50.0031\n",
      "     8   392897.4284             nan     0.1000 -109.6920\n",
      "     9   391537.8979             nan     0.1000 -652.4144\n",
      "    10   390466.0648             nan     0.1000 -607.8502\n",
      "    20   379584.6021             nan     0.1000 -1055.6703\n",
      "    40   367265.2025             nan     0.1000 -756.1819\n",
      "    50   363102.8449             nan     0.1000 -1591.2676\n",
      "\n",
      "+ Fold1: C=1 \n",
      "- Fold1: C=1 \n",
      "+ Fold2: C=1 \n",
      "- Fold2: C=1 \n",
      "+ Fold3: C=1 \n",
      "- Fold3: C=1 \n",
      "+ Fold4: C=1 \n",
      "- Fold4: C=1 \n",
      "+ Fold5: C=1 \n",
      "- Fold5: C=1 \n",
      "Aggregating results\n",
      "Fitting final model on full training set\n"
     ]
    }
   ],
   "source": [
    "# iterate through analyses and create each model, also validate versus test set\n",
    "#set seed for reproducibility\n",
    "set.seed(85)\n",
    "\n",
    "results_df <- data_frame(model=as.character(), validity=as.numeric())\n",
    "models <- list()\n",
    "for (j in 1:length(algo_vec)) {\n",
    "    resultName <- paste0(\"JP\",\"-\",algo_vec[j])\n",
    "    models[[resultName]] <- train(  \n",
    "      tweet_popularity ~ .,\n",
    "      tuneLength=5,\n",
    "      data=training_df,\n",
    "      method=algo_vec[j],\n",
    "      preProcess=c(\"zv\"),\n",
    "      trControl=trainControl(method=\"cv\", number=5, verboseIter=T, index=index)\n",
    "    )\n",
    "        \n",
    "    results_df <- bind_rows(results_df, data_frame(\n",
    "      model=resultName,\n",
    "      validity=cor(predict(models[[resultName]], test_df), pull(test_df, tweet_popularity))\n",
    "    ))\n",
    "    \n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our models, we can look at the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>model</th><th scope=col>validity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>JP-glmnet   </td><td>0.1890466   </td></tr>\n",
       "\t<tr><td>JP-gbm      </td><td>0.2658123   </td></tr>\n",
       "\t<tr><td>JP-svmLinear</td><td>0.1456513   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " model & validity\\\\\n",
       "\\hline\n",
       "\t JP-glmnet    & 0.1890466   \\\\\n",
       "\t JP-gbm       & 0.2658123   \\\\\n",
       "\t JP-svmLinear & 0.1456513   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| model | validity |\n",
       "|---|---|\n",
       "| JP-glmnet    | 0.1890466    |\n",
       "| JP-gbm       | 0.2658123    |\n",
       "| JP-svmLinear | 0.1456513    |\n",
       "\n"
      ],
      "text/plain": [
       "  model        validity \n",
       "1 JP-glmnet    0.1890466\n",
       "2 JP-gbm       0.2658123\n",
       "3 JP-svmLinear 0.1456513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#examine results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These validity values are the correlation between predicted tweet popularity scores from each of these algorithms and the actual tweet popularity scores in the holdout data.\n",
    "\n",
    "Also remember that these numbers are likely to change based on the original validation splits. If you change your seed, these numbers will change (although, usually slightly). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll want to unpack what variables (words) were most useful in each of these models. We can do this using Caret's **varImp()** function, which calculates variable importance depending on the model. See https://topepo.github.io/caret/variable-importance.html for more detials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$`JP-glmnet`\n",
       "glmnet variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 203)\n",
       "\n",
       "                    Overall\n",
       "interested      100.0000000\n",
       "language         94.5108672\n",
       "hugomunsterberg  88.2406644\n",
       "booth            84.2908801\n",
       "poster           61.0261101\n",
       "love             36.5066758\n",
       "employee         32.5961372\n",
       "forward          21.6006120\n",
       "talentmetrics    18.3413106\n",
       "teamsiop         12.4631258\n",
       "sessions          6.9233307\n",
       "change            6.6213294\n",
       "humanresources    5.8304336\n",
       "orgdev            2.3807507\n",
       "make              1.5452042\n",
       "today             0.9607775\n",
       "week              0.0977765\n",
       "business          0.0811024\n",
       "awesome           0.0004248\n",
       "employees         0.0000000\n",
       "\n",
       "$`JP-gbm`\n",
       "gbm variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 203)\n",
       "\n",
       "              Overall\n",
       "make           100.00\n",
       "sioptweets      98.83\n",
       "week            83.06\n",
       "booth           72.66\n",
       "language        66.00\n",
       "excited         63.70\n",
       "looking         58.97\n",
       "just            57.45\n",
       "team            56.60\n",
       "can             56.22\n",
       "need            48.00\n",
       "forward         47.51\n",
       "conference      44.21\n",
       "`next`          35.16\n",
       "research        34.73\n",
       "talentmetrics   33.06\n",
       "using           30.11\n",
       "leadership      26.72\n",
       "students        26.42\n",
       "futureofwork    26.19\n",
       "\n",
       "$`JP-svmLinear`\n",
       "loess r-squared variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 203)\n",
       "\n",
       "                Overall\n",
       "hugomunsterberg  100.00\n",
       "language          91.05\n",
       "booth             82.26\n",
       "interested        68.44\n",
       "poster            63.11\n",
       "talentmetrics     45.67\n",
       "love              40.36\n",
       "employee          37.04\n",
       "humanresources    36.10\n",
       "teamsiop          32.69\n",
       "team              31.09\n",
       "sessions          29.78\n",
       "hrtribe           28.70\n",
       "forward           28.56\n",
       "sioptweets        28.14\n",
       "make              26.36\n",
       "content           26.06\n",
       "going             23.97\n",
       "week              23.42\n",
       "today             22.74\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#examine top 20 vars/model\n",
    "options(scipen=999) #disable scientific notation for better interpretability\n",
    "lapply(models, varImp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that many of these rankings changed depending on the modeling approach. This is one reason why interpretation becomes more difficult. It's also not clear _why_ some of these words were more predictive than others, just that they were. However, it is undeniable that tweeting about Hugo Munsterberg directly causes tweet popularity! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Some final considerations:\n",
    "* Data does not have to be “big” to benefit from these approaches\n",
    "* Interpretation still matters\n",
    "* These techniques are far from perfect\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
